{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb802d9-da65-4cbb-8bb0-e1b4c75b2011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all required libraries at the beginning\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, \n",
    "                             f1_score, roc_auc_score, confusion_matrix, \n",
    "                             classification_report, roc_curve, auc)\n",
    "\n",
    "import shap\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "sns.set_palette(\"Set2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16127f4-4ee9-465c-9cfe-e2bfecf4ab1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# https://www.kaggle.com/c/home-credit-default-risk/data\n",
    "print(\"Loading application data...\")\n",
    "\n",
    "# Load data\n",
    "app_data = pd.read_csv('application_train.csv')\n",
    "\n",
    "print(\"Application Data Shape:\", app_data.shape)\n",
    "print(\"\\nFirst few rows of Application Data:\")\n",
    "print(app_data.head())\n",
    "\n",
    "print(\"\\nDataset Info:\")\n",
    "print(app_data.info())\n",
    "\n",
    "print(\"\\nTarget Variable Distribution:\")\n",
    "print(app_data['TARGET'].value_counts())\n",
    "print(f\"Default Rate: {app_data['TARGET'].mean():.4f}\")\n",
    "\n",
    "missing_values = app_data.isnull().sum()\n",
    "missing_percent = (missing_values / len(app_data)) * 100\n",
    "missing_df = pd.DataFrame({'Missing Values': missing_values, 'Percentage': missing_percent})\n",
    "missing_df = missing_df[missing_df['Missing Values'] > 0].sort_values('Percentage', ascending=False)\n",
    "\n",
    "print(\"\\nColumns with missing values:\")\n",
    "print(missing_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f9fb72-abdc-486e-8730-f645523921e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = app_data.copy()\n",
    "\n",
    "numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "if 'TARGET' in numerical_cols:\n",
    "    numerical_cols.remove('TARGET')\n",
    "\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print(f\"Numerical columns: {len(numerical_cols)}\")\n",
    "print(f\"Categorical columns: {len(categorical_cols)}\")\n",
    "\n",
    "num_imputer = SimpleImputer(strategy='median')\n",
    "df[numerical_cols] = num_imputer.fit_transform(df[numerical_cols])\n",
    "\n",
    "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "df[categorical_cols] = cat_imputer.fit_transform(df[categorical_cols])\n",
    "\n",
    "print(\"\\nMissing values after handling:\")\n",
    "print(df.isnull().sum().sum())\n",
    "\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col].astype(str))\n",
    "    label_encoders[col] = le\n",
    "\n",
    "print(\"\\nCategorical variables encoded.\")\n",
    "\n",
    "df['INCOME_TO_CREDIT_RATIO'] = df['AMT_INCOME_TOTAL'] / df['AMT_CREDIT']\n",
    "df['ANNUITY_TO_INCOME_RATIO'] = df['AMT_ANNUITY'] / df['AMT_INCOME_TOTAL']\n",
    "df['CREDIT_TO_ANNUITY_RATIO'] = df['AMT_CREDIT'] / df['AMT_ANNUITY']\n",
    "df['DAYS_EMPLOYED_PERCENT'] = df['DAYS_EMPLOYED'] / df['DAYS_BIRTH']\n",
    "\n",
    "df = df.replace([np.inf, -np.inf], np.nan)\n",
    "df = df.fillna(df.median())\n",
    "\n",
    "print(\"Feature engineering completed.\")\n",
    "\n",
    "X = df.drop('TARGET', axis=1)\n",
    "y = df['TARGET']\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb950a49-1126-4b7c-9daf-ea0de872e709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "target_counts = y.value_counts()\n",
    "plt.bar(['Repaid (0)', 'Default (1)'], target_counts.values)\n",
    "plt.title('Loan Repayment Status Distribution')\n",
    "plt.ylabel('Count')\n",
    "for i, v in enumerate(target_counts.values):\n",
    "    plt.text(i, v + 1000, str(v), ha='center')\n",
    "plt.show()\n",
    "\n",
    "# Correlation with target\n",
    "correlations = X.corrwith(y).abs().sort_values(ascending=False)\n",
    "top_correlations = correlations.head(10)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "top_correlations.plot(kind='bar')\n",
    "plt.title('Top 10 Features Correlated with Target')\n",
    "plt.ylabel('Absolute Correlation')\n",
    "plt.show()\n",
    "\n",
    "# Distribution of important features by target\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# AMT_INCOME_TOTAL\n",
    "axes[0, 0].hist(X[y == 0]['AMT_INCOME_TOTAL'].apply(lambda x: min(x, 1000000)), bins=50, alpha=0.7, label='Repaid')\n",
    "axes[0, 0].hist(X[y == 1]['AMT_INCOME_TOTAL'].apply(lambda x: min(x, 1000000)), bins=50, alpha=0.7, label='Default')\n",
    "axes[0, 0].set_title('Income Distribution by Repayment Status')\n",
    "axes[0, 0].set_xlabel('Income (capped at 1M)')\n",
    "axes[0, 0].set_ylabel('Count')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# AMT_CREDIT\n",
    "axes[0, 1].hist(X[y == 0]['AMT_CREDIT'].apply(lambda x: min(x, 2000000)), bins=50, alpha=0.7, label='Repaid')\n",
    "axes[0, 1].hist(X[y == 1]['AMT_CREDIT'].apply(lambda x: min(x, 2000000)), bins=50, alpha=0.7, label='Default')\n",
    "axes[0, 1].set_title('Credit Amount Distribution by Repayment Status')\n",
    "axes[0, 1].set_xlabel('Credit Amount (capped at 2M)')\n",
    "axes[0, 1].set_ylabel('Count')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# DAYS_BIRTH (convert to years)\n",
    "axes[1, 0].hist((-X[y == 0]['DAYS_BIRTH'] / 365).apply(lambda x: min(x, 70)), bins=50, alpha=0.7, label='Repaid')\n",
    "axes[1, 0].hist((-X[y == 1]['DAYS_BIRTH'] / 365).apply(lambda x: min(x, 70)), bins=50, alpha=0.7, label='Default')\n",
    "axes[1, 0].set_title('Age Distribution by Repayment Status')\n",
    "axes[1, 0].set_xlabel('Age (capped at 70)')\n",
    "axes[1, 0].set_ylabel('Count')\n",
    "axes[1, 0].legend()\n",
    "\n",
    "# INCOME_TO_CREDIT_RATIO\n",
    "axes[1, 1].hist(X[y == 0]['INCOME_TO_CREDIT_RATIO'].apply(lambda x: min(x, 5)), bins=50, alpha=0.7, label='Repaid')\n",
    "axes[1, 1].hist(X[y == 1]['INCOME_TO_CREDIT_RATIO'].apply(lambda x: min(x, 5)), bins=50, alpha=0.7, label='Default')\n",
    "axes[1, 1].set_title('Income to Credit Ratio by Repayment Status')\n",
    "axes[1, 1].set_xlabel('Income to Credit Ratio (capped at 5)')\n",
    "axes[1, 1].set_ylabel('Count')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Correlation heatmap of top features\n",
    "top_features = top_correlations.index.tolist()[:10]\n",
    "if 'TARGET' in top_features:\n",
    "    top_features.remove('TARGET')\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "corr_matrix = X[top_features].corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0)\n",
    "plt.title('Correlation Heatmap of Top Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c36670f-c3ad-457b-919d-f0468c21c152",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Class distribution before handling: {y.value_counts()}\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(f\"Class distribution after SMOTE: {pd.Series(y_train_resampled).value_counts()}\")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_resampled)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23f7dc3-fb24-4abd-bd63-822091eeb7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training models...\")\n",
    "\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, class_weight='balanced'),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42, class_weight='balanced'),\n",
    "    'XGBoost': XGBClassifier(random_state=42, scale_pos_weight=(len(y_train_resampled) - sum(y_train_resampled)) / sum(y_train_resampled)),\n",
    "    'LightGBM': LGBMClassifier(random_state=42, class_weight='balanced')\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "\n",
    "    if name in ['Logistic Regression', 'Random Forest']:\n",
    "        model.fit(X_train_scaled, y_train_resampled)\n",
    "    else:\n",
    "        model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "    if name in ['Logistic Regression', 'Random Forest']:\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    else:\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "    results[name] = {\n",
    "        'model': model,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'roc_auc': roc_auc,\n",
    "        'y_pred': y_pred,\n",
    "        'y_pred_proba': y_pred_proba\n",
    "    }\n",
    "    \n",
    "    print(f\"{name} - Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}, ROC-AUC: {roc_auc:.4f}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': list(results.keys()),\n",
    "    'Accuracy': [results[m]['accuracy'] for m in results],\n",
    "    'Precision': [results[m]['precision'] for m in results],\n",
    "    'Recall': [results[m]['recall'] for m in results],\n",
    "    'F1-Score': [results[m]['f1'] for m in results],\n",
    "    'ROC-AUC': [results[m]['roc_auc'] for m in results]\n",
    "})\n",
    "\n",
    "print(\"\\nModel Performance Comparison:\")\n",
    "print(comparison_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07906df6-cb5d-426b-b57e-61b433ed000f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC-AUC']\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    values = [results[m][metric.lower()] for m in results]\n",
    "    axes[i].bar(results.keys(), values)\n",
    "    axes[i].set_title(metric)\n",
    "    axes[i].tick_params(axis='x', rotation=45)\n",
    "\n",
    "    for j, v in enumerate(values):\n",
    "        axes[i].text(j, v + 0.01, f'{v:.3f}', ha='center')\n",
    "\n",
    "if len(metrics) < len(axes):\n",
    "    axes[-1].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "for name, result in results.items():\n",
    "    fpr, tpr, _ = roc_curve(y_test, result['y_pred_proba'])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label=f'{name} (AUC = {roc_auc:.3f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "best_model_name = max(results, key=lambda x: results[x]['f1'])\n",
    "best_model = results[best_model_name]['model']\n",
    "y_pred_best = results[best_model_name]['y_pred']\n",
    "\n",
    "print(f\"Best model: {best_model_name}\")\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "cm = confusion_matrix(y_test, y_pred_best)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(f'Confusion Matrix - {best_model_name}')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nClassification Report - {best_model_name}:\")\n",
    "print(classification_report(y_test, y_pred_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c871b69b-649e-49a5-b1a4-bea7db7a886a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if best_model_name in ['Logistic Regression', 'Random Forest']:\n",
    "    explainer = shap.Explainer(best_model, X_train_scaled)\n",
    "    shap_values = explainer(X_test_scaled)\n",
    "else:\n",
    "    explainer = shap.Explainer(best_model, X_train_resampled)\n",
    "    shap_values = explainer(X_test)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "shap.summary_plot(shap_values, X_test, plot_type=\"bar\", max_display=15)\n",
    "plt.title(f'Global Feature Importance - {best_model_name}')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "shap.summary_plot(shap_values, X_test, max_display=15)\n",
    "plt.title(f'Feature Impact on Model Output - {best_model_name}')\n",
    "plt.show()\n",
    "\n",
    "default_indices = np.where(y_pred_best == 1)[0]\n",
    "if len(default_indices) > 0:\n",
    "    instance_idx = default_indices[0]\n",
    "    print(f\"Force plot for instance {instance_idx} (predicted as default):\")\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    shap.force_plot(\n",
    "        explainer.expected_value, \n",
    "        shap_values.values[instance_idx], \n",
    "        X_test.iloc[instance_idx] if best_model_name in ['XGBoost', 'LightGBM'] else pd.DataFrame(X_test_scaled).iloc[instance_idx],\n",
    "        matplotlib=True,\n",
    "        show=False\n",
    "    )\n",
    "    plt.title(f'SHAP Force Plot for Instance {instance_idx} - {best_model_name}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"\\nFeature values for instance {instance_idx}:\")\n",
    "    if best_model_name in ['XGBoost', 'LightGBM']:\n",
    "        display(X_test.iloc[instance_idx:instance_idx+1])\n",
    "    else:\n",
    "        display(pd.DataFrame(X_test_scaled, columns=X.columns).iloc[instance_idx:instance_idx+1])\n",
    "else:\n",
    "    print(\"No instances predicted as default in the test set.\")\n",
    "\n",
    "feature_importance = np.abs(shap_values.values).mean(0)\n",
    "most_important_feature_idx = np.argmax(feature_importance)\n",
    "most_important_feature = X.columns[most_important_feature_idx]\n",
    "\n",
    "print(f\"Most important feature: {most_important_feature}\")\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "shap.dependence_plot(\n",
    "    most_important_feature_idx, \n",
    "    shap_values.values, \n",
    "    X_test if best_model_name in ['XGBoost', 'LightGBM'] else pd.DataFrame(X_test_scaled, columns=X.columns),\n",
    "    interaction_index=None\n",
    ")\n",
    "plt.title(f'Dependence Plot for {most_important_feature} - {best_model_name}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8319bfe7-f8bc-457f-9a3a-760b1c1d2839",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09eec562-c777-4196-8dcc-677b28737a5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e46c8a-569a-4eb7-9a13-1b712e75f489",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea21db7-6e80-4c02-a316-d0c819ffac8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bf183e-a566-4a0b-a877-7a43fcf55e3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0f3642-4d01-45e3-9d63-2e6ccf9ea968",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
